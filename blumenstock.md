# Response to Blumenstock - Don't forget about humans in data for development

## Question
Joshua Blumenstock states that a humbler data science could transform international development while also limiting the number of alleged silver bullets that have missed their mark in recent years. Describe the promise, pitfalls and ways forward Blumenstock uses as the foundation for his thesis.

Additionally, consider the following statements from three of your classmates regarding this article.

“Good intent is not enough in data science when dealing with the problems which determine people’s experiences” Anna Raymond

“Transparency is the underlying issue to many of these problems, so an increase in this on both ends (data based issues & human based issues) could lead to better results” Nira Nair

“In lieu of such drastic potential for promoting applications yet demoralizing hinderances, the balancing act can become difficult.” Kayla Seggelke

How do you respond to these ideas regarding “good intent”, “transparency” and the difficult “balancing act” when considering the intersection of human development with data science?

## Response
The promise that Blumenstock uses as the foundation for his thesis is that already the use of data science has helped transform international development in the world. An example of this would be from the data from mobile phones which have been used to transform consumer lending.  Another would be the connection of advertisements to people online from companies that use similar algorithims.  The pitfalls of data science so far that Blumenstock stated are the unanticipated effects, the lack of validation, biased algorithms, and the lack of regulation. An example of an unanticipated effect is that big data sometimes helps the empowered over the vulnerable people. The use of digital credit is an example of this.  Digital credit can be useful to some, but for those in poverty digital credit usually traps people in debt.  The lack of validation is also a pitfall due to the lack of evidence in the longevity of algorithms.  Some algorithms have not been tested for a long period of time, so there is doubt and a lack of evidence that these algorithms will still be accurate after some time. Biased algorithms are another pitfall because some use biased or patchy data which can marginalize the poorly represented people in the population.  An example of this was in navigation apps which are used to understand urban mobility, but because a part of the population do not own smart phones or phones, the navigation app data is biased in measuring urban mobility.  Finally, the lack of regulation was the last pitfall stated by Blumenstock.  In more developed countries the lack of regulation is not as large of a problem as it is in lesser developed countries.  Many restriction laws on data collection/privacy do not exist, so people in underdeveloped countries are more at risk. Blumestock states three ways forward, and those ways are to validate, customize and deepen collaboration. Validating is a step forward because new data should not replace old data, but it should work with it.  In order to take a step forward new data should be used to complement old data instead of replacing it.  The second step forward is through customization,  and this is done through more research and developing better algorithms to work for different populations.  Blumenstock states that most technology being used is designed for first-world purpose, so it is not as effective in less developed countries. Due to this we must customize our technology to be more useful in other parts of the world.  Finally, the last step forward that Blumenstock states is the deepening of collaboration.  He states that we must bring together all our data scientists and those involved with machine learning in order to create better efforts.
